# Biomni Docker Environment Configuration
# Copy this file to .env and fill in your API keys

# ============================================
# LLM API Keys (At least one required)
# ============================================

# OpenAI
OPENAI_API_KEY=

# Anthropic Claude
ANTHROPIC_API_KEY=

# Azure OpenAI
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_DEPLOYMENT_NAME=

# Google Gemini
GOOGLE_API_KEY=

# Groq
GROQ_API_KEY=

# AWS Bedrock
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_DEFAULT_REGION=us-east-1

# ============================================
# Biomni Configuration
# ============================================

# Default LLM provider (openai, anthropic, azure, google, groq, bedrock)
DEFAULT_LLM_PROVIDER=openai

# Default model to use
DEFAULT_LLM_MODEL=gpt-4

# Logging level (DEBUG, INFO, WARNING, ERROR)
BIOMNI_LOG_LEVEL=INFO

# Maximum parallel workers
BIOMNI_MAX_WORKERS=4

# Memory limit for agents (in GB)
BIOMNI_MEMORY_LIMIT=32

# ============================================
# Data Directories (Host machine paths)
# ============================================

# Data lake directory (where Biomni data is stored)
BIOMNI_DATA_DIR=./data/data_lake

# Cache directory
BIOMNI_CACHE_DIR=./data/cache

# Results directory
BIOMNI_RESULTS_DIR=./data/results

# Logs directory
BIOMNI_LOGS_DIR=./data/logs

# ============================================
# Local Mount Configuration (Mac/Linux)
# ============================================

# Skip S3 downloads when using local mounted data
BIOMNI_SKIP_DOWNLOAD=true

# Local data path on your Mac (contains data_lake and benchmark folders)
# This path will be mounted into containers
BIOMNI_LOCAL_DATA_PATH=./data

# Enable local mount mode (uses biomni_local_mount.py wrapper)
BIOMNI_USE_LOCAL_MOUNT=true

# ============================================
# Jupyter Configuration (for dev profile)
# ============================================

# Jupyter access token
JUPYTER_TOKEN=biomni

# Jupyter port (default 8888)
JUPYTER_PORT=8888

# ============================================
# Optional Services Configuration
# ============================================

# Redis Configuration (if using cache profile)
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=

# MinIO Configuration (if using storage profile)
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=
MINIO_SECRET_KEY=

# ============================================
# MCP (Model Context Protocol) Configuration
# ============================================

# GitHub MCP Server
GITHUB_TOKEN=

# Other MCP servers can be configured here
MCP_SERVER_ENABLED=false

# ============================================
# NIBR-Specific Configuration (Enterprise)
# ============================================

# NIBR Data Catalog endpoint
NIBR_CATALOG_ENDPOINT=

# NIBR Authentication
NIBR_AUTH_ENDPOINT=
NIBR_CLIENT_ID=
NIBR_CLIENT_SECRET=

# Team-specific S3 buckets (for data layer)
NIBR_S3_BUCKET=
NIBR_S3_REGION=us-east-1

# ============================================
# Resource Limits
# ============================================

# CPU limit (number of cores)
CPU_LIMIT=8

# Memory limit (e.g., 32G)
MEMORY_LIMIT=32G

# GPU configuration (if available)
NVIDIA_VISIBLE_DEVICES=all
CUDA_VISIBLE_DEVICES=0

# ============================================
# Security Configuration
# ============================================

# Enable security features
ENABLE_SECURITY=true

# Run as user (UID:GID)
USER_ID=1000
GROUP_ID=1000

# Read-only root filesystem
READ_ONLY_ROOT=false

# ============================================
# Network Configuration
# ============================================

# Network subnet
NETWORK_SUBNET=172.28.0.0/16

# Proxy configuration (if behind corporate proxy)
HTTP_PROXY=
HTTPS_PROXY=
NO_PROXY=localhost,127.0.0.1,biomni,redis,minio